{"metadata":{"kernelspec":{"display_name":".kaggle_venv","language":"python","name":".kaggle_venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_log_error,  make_scorer, roc_auc_score\nprepath = \"/home/cristobal\"\ntrainpath = prepath+\"/kaggle/input/playground-series-s3e11/train.csv\"\ntestpath = prepath+\"/kaggle/input/playground-series-s3e11/test.csv\"\noriginalpath = prepath+\"/kaggle/input/media-campaign-cost-prediction/train_dataset.csv\"\noutputpath = prepath+\"/kaggle/working/playground-series-s3e11/\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(trainpath)\ndata = data.drop(columns=[\"id\"])\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target = data.columns\nfeatures = list(features_target[:-1])\n\ncorr = data[features_target].corr()\n\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nf, ax = plt.subplots(figsize=(11, 9))\n\nsns.heatmap(corr, mask=mask, cmap=\"coolwarm\", \n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data from original dataset\noriginal_df = pd.read_csv(originalpath)\noriginal_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train test split\nx_train, x_test, y_train, y_test = train_test_split(\n    data[features], data[\"cost\"], test_size=0.30, random_state=21)\n# Add original dataset to training set\ntrain = pd.concat([x_train, y_train], axis=1)\ntrain2 = pd.concat([train, original_df])\n# Shuffle\ntrain2 = train2.sample(frac=1)\nx_train_2 = train2[features]\ny_train_2 = train2[\"cost\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of missing values in each column of training data\nmissing_val_count_by_column = (x_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Grid search to find good parameters\nparams_grid = { \n            \"max_depth\": [3, 6, 12, 18],\n            \"learning_rate\": [0.3, 0.01, 0.001],\n            \"gamma\": [0.1, 2, 10],#, 100, 1000],\n            \"min_child_weight\": [1, 10, 50],\n            \"reg_lambda\": [0, 50, 100],\n            \"objective\": [\"reg:squaredlogerror\", 'reg:squarederror']\n            }\n\nrmsle=make_scorer(mean_squared_log_error, greater_is_better=False, squared=False)\n\nreg_cv_1 = xgb.XGBRegressor(n_estimators=1000,\n                            early_stopping_rounds=5, \n                            eval_metric=\"rmsle\",\n                            verbosity=0\n                         )\nrandom_search = RandomizedSearchCV(estimator=reg_cv_1, \n                           param_distributions=params_grid, \n                           n_iter=100,\n                           scoring=rmsle, \n                           # n_jobs=-2, \n                           cv=5, \n                           verbose=3)\nrandom_result = random_search.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_results = pd.DataFrame(random_result.cv_results_)\n# Mean score + 2std\ngrid_results[\"worst_case_score\"] = grid_results.mean_test_score-2*grid_results.std_test_score\n# Mean score - 2std\ngrid_results[\"best_case_score\"] = grid_results.mean_test_score+2*grid_results.std_test_score\n# Show top 10 results sorted by std\nbest20 = grid_results.sort_values('rank_test_score')[:9]\nbest20.sort_values('std_test_score')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second Random Grid search to find good parameters\nparams_grid = { \n            \"max_depth\": [10, 12, 14],\n            \"learning_rate\": [0.1, 0.01, 0.06],\n            \"gamma\": [0.1, 2, 8, 15],#, 100, 1000],\n            \"min_child_weight\": [30, 50, 70],\n            \"reg_lambda\": [0, 50, 100, 150, 200],\n            }\n\nreg_cv_2 = xgb.XGBRegressor(n_estimators=1000,\n                            early_stopping_rounds=5, \n                            eval_metric=\"rmsle\",\n                            objective='reg:squarederror',\n                            verbosity=0\n                         )\nrandom_search_2 = RandomizedSearchCV(estimator=reg_cv_2, \n                           param_distributions=params_grid, \n                           n_iter=100,\n                           scoring=rmsle, \n                           n_jobs=4, \n                           cv=5, \n                           verbose=3)\nrandom_result_2 = random_search_2.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_results_2 = pd.DataFrame(random_result_2.cv_results_)\n# Mean score + 2std\ngrid_results_2[\"worst_case_score\"] = grid_results_2.mean_test_score-2*grid_results_2.std_test_score\n# Mean score - 2std\ngrid_results_2[\"best_case_score\"] = grid_results_2.mean_test_score+2*grid_results_2.std_test_score\n# Show top 10 results sorted by std\nbest20_2 = grid_results_2.sort_values('rank_test_score')[:9]\nbest20_2.sort_values('std_test_score')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Third Random Grid search to find good parameters\nparams_grid = { \n            \"max_depth\": [11, 12, 13],\n            \"learning_rate\": [ 0.01, 0.03, 0.06],\n            \"gamma\": [2, 8, 15],#, 100, 1000],\n            \"min_child_weight\": [40, 200],\n            \"reg_lambda\": [0],\n            }\n\nrmsle=make_scorer(mean_squared_log_error, greater_is_better=False, squared=False)\n\nreg_cv_3 = xgb.XGBRegressor(n_estimators=1000,\n                            early_stopping_rounds=5, \n                            eval_metric=\"rmsle\",\n                            objective='reg:squarederror',\n                            verbosity=0\n                         )\nrandom_search_3 = RandomizedSearchCV(estimator=reg_cv_3, \n                           param_distributions=params_grid, \n                           n_iter=30,\n                           scoring=rmsle, \n                           n_jobs=4, \n                           cv=5, \n                           verbose=3)\nrandom_result_3 = random_search_3.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_results_3 = pd.DataFrame(random_result_3.cv_results_)\n# Mean score + 2std\ngrid_results_3[\"worst_case_score\"] = grid_results_3.mean_test_score-2*grid_results_3.std_test_score\n# Mean score - 2std\ngrid_results_3[\"best_case_score\"] = grid_results_3.mean_test_score+2*grid_results_3.std_test_score\n# Show top 10 results sorted by std\nbest20_3 = grid_results_3.sort_values('rank_test_score')[:9]\nbest20_3.sort_values('std_test_score')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fourth Random Grid search to find good parameters\nparams_grid = { \n            \"max_depth\": [11],\n            \"learning_rate\": [0.008, 0.01, 0.03, 0.05, 0.07],\n            \"gamma\": [1, 5, 15, 20, 25],#, 100, 1000],\n            \"min_child_weight\": [30, 70, 110],\n            \"reg_lambda\": [0],\n            }\n\nrmsle=make_scorer(mean_squared_log_error, greater_is_better=False, squared=False)\n\nreg_cv_4 = xgb.XGBRegressor(n_estimators=1000,\n                            early_stopping_rounds=5, \n                            eval_metric=\"rmsle\",\n                            objective='reg:squarederror',\n                            verbosity=0\n                         )\nrandom_search_4 = RandomizedSearchCV(estimator=reg_cv_4, \n                           param_distributions=params_grid, \n                           n_iter=40,\n                           scoring=rmsle, \n                           n_jobs=4, \n                           cv=5, \n                           verbose=3)\nrandom_result_4 = random_search_4.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_results_4 = pd.DataFrame(random_result_4.cv_results_)\n# Mean score + 2std\ngrid_results_4[\"worst_case_score\"] = grid_results_4.mean_test_score-2*grid_results_4.std_test_score\n# Mean score - 2std\ngrid_results_4[\"best_case_score\"] = grid_results_4.mean_test_score+2*grid_results_4.std_test_score\n# Show top 10 results sorted by std\nbest20_4 = grid_results_4.sort_values('rank_test_score')[:9]\nbest20_4.sort_values('std_test_score')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training with best parameters\nparams = { \"n_estimators\": 10000,\n            \"max_depth\": 11,\n            \"learning_rate\": 0.01,\n            \"gamma\": 25,\n            \"min_child_weight\": 30,\n            \"reg_lambda\": 0,\n            \"eval_metric\": \"rmsle\",\n            \"early_stopping_rounds\": 20,\n            \"objective\":\"reg:squarederror\",\n            \"verbosity\": 1\n            }\n\nreg = xgb.XGBRegressor(**params)\n# start = time.time() # time at start of BDT fit\nreg.fit(x_train, y_train, eval_set=[(x_test, y_test)])\n# elapsed = time.time() - start # time after fitting BDT\n# print(\"Time taken to fit BDT: \"+str(round(elapsed,1))+\"s\") # print total time taken to fit BDT\nprint(reg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = reg.predict(x_test).flatten()\ny_pred_train = reg.predict(x_train).flatten()\nmean_squared_log_error(y_test, y_pred_test, squared=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model with original data\nparams = { \"n_estimators\": 10000,\n            \"max_depth\": 11,\n            \"learning_rate\": 0.01,\n            \"gamma\": 25,\n            \"min_child_weight\": 30,\n            \"reg_lambda\": 0,\n            \"eval_metric\": \"rmsle\",\n            \"early_stopping_rounds\": 20,\n            \"objective\":\"reg:squarederror\",\n            \"verbosity\": 1\n            }\n\nreg2 = xgb.XGBRegressor(**params)\n# start = time.time() # time at start of BDT fit\nreg2.fit(x_train_2, y_train_2, eval_set=[(x_test, y_test)])\n# elapsed = time.time() - start # time after fitting BDT\n# print(\"Time taken to fit BDT: \"+str(round(elapsed,1))+\"s\") # print total time taken to fit BDT\nprint(reg2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_2 = reg2.predict(x_test).flatten()\ny_pred_train_2 = reg2.predict(x_train).flatten()\n#logloss of the model trained with original data\nmean_squared_log_error(y_test, y_pred_test_2, squared=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data for submission\nsubmit_df = pd.read_csv(testpath)\nsubmit_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_id = submit_df[\"id\"]\n# Predict the cost of the submission data\ny_pred_submit = reg2.predict(submit_df[features]).flatten()\nsubmit_final = pd.DataFrame({\"id\": submit_id, \"Class\": y_pred_submit})\n# Save prediction\nsubmit_final.to_csv(outputpath+\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}